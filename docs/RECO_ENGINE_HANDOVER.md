# Recommendation Engine Handover - For Colleague Review

## üéØ Purpose
This document provides a handover for reviewing the recommendation engine, identifying issues, and verifying question/answer logic.

## ‚úÖ Recent Updates
- **Priority 3 (Question Meaningfulness)**: ‚úÖ COMPLETED - Removed TRL, CAPEX/OPEX, innovation focus, and sustainability focus questions. Simplified co-financing question. See `PRIORITY_3_QUESTION_MEANINGFULNESS_FIX.md` for details.

---

## üìä Current Status

### ‚úÖ What's Working
1. **Filtering Logic**: 18 filter handlers implemented (Priority 1 complete)
2. **Dynamic Scoring**: Frequency-based scoring implemented (Priority 2 complete)
3. **Question Generation**: Dynamic questions based on requirement frequencies
4. **Answer Display**: Fixed to show all answers with translations
5. **Database Connection Fixes**: Improved error handling and TypeScript module loading

### ‚ö†Ô∏è Known Issues

#### 1. **Database Connection Still Failing**
- **Status**: Using JSON fallback (`source: "fallback"`)
- **Impact**: Only 341 programs available (vs 1,024+ in database)
- **Location**: `pages/api/programs.ts` line 494
- **Fix Attempted**: Switched to dynamic `import()` instead of `require()`
- **Action Needed**: Restart dev server and check logs for specific error

#### 2. **Wizard Stops at 4 Questions**
- **Status**: Fixed in code, but may still occur if:
  - Only 4 questions generated (due to low frequency requirements)
  - Programs filtered down too quickly (‚â§5 programs remaining)
- **Location**: `features/reco/engine/questionEngine.ts` line 793-830
- **Fix Applied**: Requires minimum 5 questions, improved stopping logic
- **Action Needed**: Test in browser to verify fix works

#### 3. **DE/EN Language Mismatch**
- **Status**: Questions use translation keys, but may be missing translations
- **Location**: `features/reco/components/wizard/SmartWizard.tsx` line 404, 416
- **Issue**: Translation keys like `wizard.questions.xxx` may not exist in DE
- **Action Needed**: Verify all translation keys exist in both `shared/i18n/translations/de.json` and `en.json`

#### 4. **Low Score Distribution**
- **Status**: Scores are very low (0-5% range in tests)
- **Location**: `features/reco/engine/enhancedRecoEngine.ts` line 547-586
- **Issue**: May be too strict or missing normalization
- **Action Needed**: Review scoring algorithm, verify it's not too harsh

#### 5. **Answers Not Being Saved**
- **Status**: Fixed in code (answers now displayed)
- **Location**: `features/reco/components/wizard/SmartWizard.tsx` line 499-543
- **Action Needed**: Verify answers persist and are used in scoring

#### 6. **Question Meaningfulness** ‚ö†Ô∏è **CRITICAL**
- **Status**: Not all questions are meaningful for users
- **Location**: `features/reco/engine/questionEngine.ts` line 400-700
- **Issue**: Some questions are too technical (TRL, CAPEX/OPEX) or too vague (innovation focus)
- **Action Needed**: Review all questions, remove/simplify technical or vague ones
- **Questions to Review**: TRL level, CAPEX/OPEX, innovation focus, sustainability focus, co-financing

---

## üß™ Test Scripts Available

### 1. **Data Quality Check**
```bash
node scripts/check-data-quality.js
```
**Purpose**: Check if programs have proper `categorized_requirements`
**What to Look For**:
- Programs with requirements: Should be 100%
- Average categories per program: Should be ~18
- Eligible requirement types: Should be ~10 (for 10 questions)

### 2. **Question Generation Test**
```bash
node scripts/test-all-questions.js
```
**Purpose**: Test full question flow with all answers
**What to Look For**:
- Questions generated: Should be 10 (max)
- Filtering effectiveness: Each question should filter programs
- Question fairness: Programs without requirements should stay available

### 3. **Scoring Test**
```bash
node scripts/test-scoring-improvements.js
```
**Purpose**: Test scoring algorithm
**What to Look For**:
- Score distribution: Should be varied (not all 100%)
- Scores should be 0-100% range
- Rare requirements should score higher than common ones

### 4. **Filtering Test**
```bash
node scripts/test-filtering-improvements.js
```
**Purpose**: Test all 18 filter handlers
**What to Look For**:
- Effective filters: Should filter programs
- Ineffective filters: May be 0% (expected if programs don't have requirement)
- New filters (Priority 1): Should work correctly

### 5. **Database Connection Test**
```bash
node scripts/test-db-connection.js
```
**Purpose**: Test database connection
**What to Look For**:
- DATABASE_URL: Should be set
- Connection: Should succeed
- Tables: Should be accessible

### 6. **API Connection Test**
```bash
node scripts/test-api-connection.js
```
**Purpose**: Test API endpoint
**What to Look For**:
- Response status: 200 OK
- Source: "database" or "fallback"
- Programs count: Should match data source

---

## üîç Critical Areas to Review

### 1. **Question Generation Logic**
**File**: `features/reco/engine/questionEngine.ts`
**Lines**: 105-140 (generateQuestions), 771-830 (getNextQuestion)

**Check**:
- ‚úÖ Are questions generated dynamically based on frequencies?
- ‚ö†Ô∏è Why only 4 questions? Check `MIN_FREQUENCY` threshold (line 111)
- ‚ö†Ô∏è Why stops early? Check stopping logic (line 793-830)

**Test**:
```bash
node scripts/test-all-questions.js
```

### 2. **Answer Mapping & Translation**
**File**: `features/reco/components/wizard/SmartWizard.tsx`
**Lines**: 404, 416, 500-543

**Check**:
- ‚úÖ Are translation keys correct? (`wizard.questions.xxx`, `wizard.options.xxx`)
- ‚ö†Ô∏è Are all keys in DE translations? Check `shared/i18n/translations/de.json`
- ‚ö†Ô∏è Are answers being saved correctly? Check state.answers

**Test**: Open browser, check console for translation errors

### 2b. **Question Meaningfulness** ‚ö†Ô∏è **CRITICAL**
**File**: `features/reco/engine/questionEngine.ts`
**Lines**: 400-700 (createQuestionFromRequirement)

**Check**:
- ‚ö†Ô∏è **Are questions meaningful for users?** (not too technical, not jargon)
- ‚ö†Ô∏è **Are questions clear and understandable?** (users can answer without specialized knowledge)
- ‚ö†Ô∏è **Are questions relevant for funding discovery?** (help find funding, not just decorative)
- ‚ö†Ô∏è **Are there duplicate or overlapping questions?** (e.g., sector vs industry)
- ‚ö†Ô∏è **Should some questions be removed?** (TRL, CAPEX/OPEX, overly vague questions)

**Test**: 
- Open browser, answer questions as a normal user
- Check: Would you understand "TRL level"? "CAPEX/OPEX"? "Innovation focus"?
- Review each question: Does it make sense? Is it relevant?
- **Likely to remove**: TRL level, CAPEX/OPEX, innovation focus, sustainability focus

### 3. **Scoring Algorithm**
**File**: `features/reco/engine/enhancedRecoEngine.ts`
**Lines**: 400-586 (scoreCategorizedRequirements), 547-586 (normalization)

**Check**:
- ‚úÖ Is scoring dynamic (frequency-based)?
- ‚ö†Ô∏è Are scores too low? Check normalization logic
- ‚ö†Ô∏è Are penalties too harsh? Check penalty calculation (line 570)

**Test**:
```bash
node scripts/test-scoring-improvements.js
```

### 4. **Filtering Logic**
**File**: `features/reco/engine/questionEngine.ts`
**Lines**: 874-1311 (filterPrograms)

**Check**:
- ‚úÖ Are all 18 filters implemented?
- ‚ö†Ô∏è Are filters effective? Check filtering percentages
- ‚ö†Ô∏è Do filters match enhancedRecoEngine logic?

**Test**:
```bash
node scripts/test-filtering-improvements.js
```

### 5. **Database Connection**
**File**: `pages/api/programs.ts`
**Lines**: 270-518

**Check**:
- ‚ö†Ô∏è Is DATABASE_URL set? Check `.env.local`
- ‚ö†Ô∏è Are modules loading? Check for "Cannot find module" errors
- ‚ö†Ô∏è Is connection successful? Check server logs

**Test**:
```bash
node scripts/test-db-connection.js
```

---

## üêõ Specific Issues to Investigate

### Issue 1: Wizard Stops at 4 Questions
**Symptoms**: Wizard stops after 4 questions
**Possible Causes**:
1. Only 4 questions generated (frequency threshold too high)
2. Programs filtered down too quickly (‚â§5 remaining)
3. All questions answered (but only 4 generated)

**Investigation Steps**:
1. Run `node scripts/check-data-quality.js` - Check eligible requirement types
2. Check console logs: `üìä Analyzed X unique requirement types`
3. Check `MIN_FREQUENCY` threshold (line 111): `Math.max(3, Math.floor(programs.length * 0.05))`
4. With 341 programs, threshold = 17 programs (5%)
5. If only 4 types meet threshold ‚Üí only 4 questions generated

**Fix Options**:
- Lower `MIN_FREQUENCY` threshold (e.g., 3% instead of 5%)
- Reduce minimum programs for frequency calculation
- Ensure all 10 question slots are filled

### Issue 2: DE/EN Language Mismatch
**Symptoms**: Questions/answers show in wrong language or show raw keys
**Possible Causes**:
1. Missing translation keys in DE
2. Translation keys don't match question IDs
3. Language detection not working

**Investigation Steps**:
1. Check `shared/i18n/translations/de.json` - Verify all `wizard.questions.*` keys exist
2. Check `shared/i18n/translations/en.json` - Compare with DE
3. Check browser console for missing translation warnings
4. Verify `useI18n()` hook is working (check locale)

**Fix Options**:
- Add missing translation keys to DE
- Ensure question IDs match translation keys
- Verify language detection logic

### Issue 3: Answers Not Being Saved
**Symptoms**: Answers don't appear or disappear
**Possible Causes**:
1. State not updating correctly
2. Answers not passed to scoring
3. Answers cleared on navigation

**Investigation Steps**:
1. Check `handleAnswer()` function (line 220) - Verify state update
2. Check answer display (line 499-543) - Verify rendering
3. Check `processResults()` (line 261) - Verify answers passed to scoring
4. Check browser console for state updates

**Fix Options**:
- Verify state management
- Check answer persistence
- Ensure answers are passed to `scoreProgramsEnhanced()`

### Issue 4: Low Scores
**Symptoms**: All programs scoring 0-5%
**Possible Causes**:
1. Normalization too strict
2. Penalties too harsh
3. Matching logic too strict
4. Missing requirement data

**Investigation Steps**:
1. Run `node scripts/test-scoring-improvements.js` - Check score distribution
2. Check normalization logic (line 547-586)
3. Check penalty calculation (line 570)
4. Verify requirement matching (line 447-505)

**Fix Options**:
- Adjust normalization formula
- Reduce penalty percentages
- Improve matching logic
- Verify requirement data quality

---

## üìù Question & Answer Logic Review

### ‚ö†Ô∏è CRITICAL: Question Meaningfulness Check

**Not all questions are meaningful for the wizard!**

Some questions may be:
- ‚ùå Too technical/jargon-heavy for users
- ‚ùå Not relevant for the funding discovery flow
- ‚ùå Confusing or unclear
- ‚ùå Too specific (e.g., "TRL level" - users may not know what this is)
- ‚ùå Duplicate or overlapping with other questions

**Questions to Review**:
1. **Location** ‚úÖ - Meaningful (essential for funding)
2. **Company Age** ‚úÖ - Meaningful (stage-based programs)
3. **Revenue** ‚ö†Ô∏è - Check if meaningful (some users may not know)
4. **Team Size** ‚ö†Ô∏è - Check if meaningful (may be too specific)
5. **Research Focus** ‚ö†Ô∏è - Check if meaningful (research vs commercial)
6. **Consortium** ‚ö†Ô∏è - Check if meaningful (partnership requirements)
7. **Innovation Focus** ‚ö†Ô∏è - Check if meaningful (too vague?)
8. **Sustainability Focus** ‚ö†Ô∏è - Check if meaningful (too specific?)
9. **Technology Focus** ‚ö†Ô∏è - Check if meaningful (jargon?)
10. **TRL Level** ‚ùå - **LIKELY NOT MEANINGFUL** (too technical)
11. **Co-financing** ‚ö†Ô∏è - Check if meaningful (users may not understand)
12. **Company Type** ‚úÖ - Meaningful (startup vs SME)
13. **Sector** ‚ö†Ô∏è - Check if meaningful (overlaps with industry?)
14. **Market Size** ‚ö†Ô∏è - Check if meaningful (too vague?)
15. **Investment Type (CAPEX/OPEX)** ‚ùå - **LIKELY NOT MEANINGFUL** (too technical)

**Review Criteria**:
- ‚úÖ Question is clear and understandable
- ‚úÖ Question is relevant for funding discovery
- ‚úÖ User can answer without specialized knowledge
- ‚úÖ Question actually filters programs (not just decorative)
- ‚úÖ Question doesn't duplicate other questions

**Action Items**:
1. Review each question in browser: Does it make sense?
2. Check if users would understand the question
3. Verify question filters programs effectively
4. Consider removing questions that are:
   - Too technical (TRL, CAPEX/OPEX)
   - Too vague (innovation focus, sustainability focus)
   - Not relevant for funding discovery
   - Overlapping with other questions

### Question Generation Flow
1. **Analyze Requirements** (`analyzeRequirements()`)
   - Scans all programs' `categorized_requirements`
   - Calculates frequency of each requirement type
   - Stores in `requirementFrequencies` array

2. **Generate Questions** (`generateQuestions()`)
   - Filters by `MIN_FREQUENCY` threshold (5% of programs)
   - Maps requirement types to question IDs
   - Creates questions with translation keys
   - Limits to 10 questions (MAX_QUESTIONS)
   - ‚ö†Ô∏è **Doesn't check if questions are meaningful** - just generates based on frequency

3. **Get Next Question** (`getNextQuestion()`)
   - Filters programs based on answers
   - Returns first unanswered required question
   - Then returns first unanswered optional question
   - Stops if filtered down significantly or all answered

### Answer Mapping
**Question IDs** ‚Üí **Answer Keys**:
- `location` ‚Üí `answers.location`
- `company_age` ‚Üí `answers.company_age`
- `revenue` ‚Üí `answers.revenue`
- `team_size` ‚Üí `answers.team_size`
- etc.

**Translation Keys**:
- Questions: `wizard.questions.{questionId}`
- Options: `wizard.options.{optionValue}`

### Filtering Logic
**Fair Filtering** (programs without requirements stay available):
- If program has no requirement ‚Üí returns `true` (included)
- If program has requirement ‚Üí checks if user answer matches
- This prevents unfair exclusion

**Check**: Verify filters don't exclude programs without requirements

### Question Meaningfulness Review Process

**Step 1: List All Generated Questions**
```bash
# Check what questions are generated
node scripts/test-all-questions.js
# Look for: "Questions that will be generated: X"
```

**Step 2: Test Each Question in Browser**
1. Open `http://localhost:3000/reco`
2. Answer questions one by one
3. For each question, ask:
   - ‚ùì Is this question clear and understandable?
   - ‚ùì Can a typical user answer this without specialized knowledge?
   - ‚ùì Does this question help find funding?
   - ‚ùì Is this question relevant at this stage of the wizard?

**Step 3: Check Question Effectiveness**
```bash
node scripts/test-filtering-improvements.js
# Check which questions actually filter programs
# Questions with 0% filtered may not be meaningful OR programs don't have requirement
```

**Step 4: Review Question Content**
- Check `features/reco/engine/questionEngine.ts` line 400-700
- For each question, verify:
  - Translation key exists and is user-friendly
  - Options are clear and not jargon
  - Question text makes sense

**Step 5: Identify Questions to Remove/Improve**

**Likely Candidates for Removal**:
- `trl_level` - Too technical (TRL = Technology Readiness Level)
- `investment_type` (CAPEX/OPEX) - Too technical
- `co_financing` - May be confusing (what does co-financing mean?)
- `sustainability_focus` - Too vague (what does this mean?)
- `innovation_focus` - Too vague (everything is innovative)

**Likely Candidates to Keep/Improve**:
- `location` ‚úÖ - Essential
- `company_age` ‚úÖ - Clear
- `company_type` ‚úÖ - Clear (startup/SME)
- `research_focus` ‚úÖ - Clear (research vs commercial)
- `consortium` ‚úÖ - Clear (partnerships)

**Questions to Simplify**:
- `revenue` ‚Üí Maybe simplify to "Do you have revenue?" (yes/no) instead of ranges
- `team_size` ‚Üí Maybe simplify to "How many people?" (small/medium/large)
- `funding_amount` ‚Üí Keep but simplify options

---

## üîß Recommended Testing Procedure

### Step 1: Data Quality Check
```bash
node scripts/check-data-quality.js
```
**Expected**:
- 341 programs (or more if database works)
- 100% have requirements
- ~10 eligible requirement types
- Average 18 categories per program

### Step 2: Question Generation Test
```bash
node scripts/test-all-questions.js
```
**Expected**:
- 10 questions generated (or fewer if not enough eligible types)
- Questions use translation keys
- Filtering works progressively

### Step 3: Filtering Test
```bash
node scripts/test-filtering-improvements.js
```
**Expected**:
- Some filters effective (filter programs)
- Some filters ineffective (0% - expected if programs don't have requirement)
- New filters (Priority 1) work correctly

### Step 4: Scoring Test
```bash
node scripts/test-scoring-improvements.js
```
**Expected**:
- Score distribution varied (not all 100%)
- Scores in 0-100% range
- Rare requirements worth more points

### Step 5: Browser Testing
1. Open `http://localhost:3000/reco`
2. Check browser console for:
   - Questions generated count
   - Filtering activity
   - Translation errors
   - Answer state updates
3. **Answer questions and verify meaningfulness**:
   - ‚ö†Ô∏è **For each question, ask: "Would a normal user understand this?"**
   - ‚ö†Ô∏è **Check if questions are too technical** (TRL, CAPEX/OPEX)
   - ‚ö†Ô∏è **Check if questions are too vague** (innovation focus, sustainability focus)
   - ‚ö†Ô∏è **Check if questions are relevant** (help find funding)
   - Answers are displayed
   - Wizard continues past 4 questions
   - Results are shown

### Step 6: Database Connection
```bash
# Check if DATABASE_URL is set
Get-Content .env.local | Select-String DATABASE_URL

# Test connection
node scripts/test-db-connection.js
```
**Expected**:
- DATABASE_URL found
- Connection successful
- Tables accessible

---

## üéØ Priority Issues to Fix

### Priority 1: Database Connection (BLOCKING)
- **Impact**: Only 341 programs vs 1,024+ in database
- **Action**: Check server logs, verify dynamic imports work after restart
- **Files**: `pages/api/programs.ts`, `pages/api/programs-ai.ts`

### Priority 2: Question Generation (USER EXPERIENCE)
- **Impact**: Only 4 questions generated (low frequency threshold)
- **Action**: Review `MIN_FREQUENCY` threshold, ensure 10 questions generated
- **Files**: `features/reco/engine/questionEngine.ts` line 111

### Priority 3: Question Meaningfulness (USER EXPERIENCE) ‚ö†Ô∏è **CRITICAL** ‚úÖ **COMPLETED**
- **Impact**: Users may not understand technical questions (TRL, CAPEX/OPEX)
- **Action**: ‚úÖ **DONE** - Removed technical/vague questions, simplified co-financing
- **Files**: `features/reco/engine/questionEngine.ts` line 400-700
- **Questions Removed**: 
  - ‚úÖ TRL level (too technical)
  - ‚úÖ CAPEX/OPEX investment type (too technical)
  - ‚úÖ Innovation focus (too vague)
  - ‚úÖ Sustainability focus (too vague)
- **Questions Improved**:
  - ‚úÖ Co-financing: Changed from percentage to yes/no question

### Priority 4: Language Translations (USER EXPERIENCE)
- **Impact**: DE/EN mismatch, missing translations
- **Action**: Verify all translation keys exist in both languages
- **Files**: `shared/i18n/translations/de.json`, `shared/i18n/translations/en.json`

### Priority 5: Scoring Algorithm (ACCURACY)
- **Impact**: Scores too low (0-5%), may not reflect actual match quality
- **Action**: Review normalization, penalty calculation
- **Files**: `features/reco/engine/enhancedRecoEngine.ts` line 547-586

---

## üìö Key Files Reference

### Core Engine Files
- `features/reco/engine/questionEngine.ts` - Question generation & filtering
- `features/reco/engine/enhancedRecoEngine.ts` - Scoring algorithm
- `features/reco/components/wizard/SmartWizard.tsx` - UI component

### API Files
- `pages/api/programs.ts` - Programs endpoint (database connection)
- `pages/api/programs-ai.ts` - AI features endpoint

### Translation Files
- `shared/i18n/translations/en.json` - English translations
- `shared/i18n/translations/de.json` - German translations

### Test Scripts
- `scripts/check-data-quality.js` - Data completeness
- `scripts/test-all-questions.js` - Question flow
- `scripts/test-scoring-improvements.js` - Scoring algorithm
- `scripts/test-filtering-improvements.js` - Filtering logic
- `scripts/test-db-connection.js` - Database connection

---

## ‚úÖ Success Criteria

### For Question Generation:
- [ ] 10 questions generated (or close to 10)
- [ ] **Questions are meaningful** (not jargon, clear, relevant)
- [ ] **Questions are user-friendly** (understandable without specialized knowledge)
- [ ] Questions filter programs effectively
- [ ] Wizard doesn't stop early (at least 5 questions)
- [ ] **No duplicate or overlapping questions**
- [ ] **No overly technical questions** (TRL, CAPEX/OPEX, etc.)

### For Answer Handling:
- [ ] Answers are saved correctly
- [ ] Answers are displayed in UI
- [ ] Answers are passed to scoring
- [ ] Translations work (DE/EN)

### For Scoring:
- [ ] Score distribution is varied (0-100%)
- [ ] Scores reflect match quality
- [ ] Rare requirements worth more
- [ ] Penalties applied correctly

### For Database:
- [ ] Connection successful
- [ ] Programs loaded from database (not fallback)
- [ ] More programs available (1,024+ vs 341)

---

## üöÄ Quick Start

1. **Check Data Quality**:
   ```bash
   node scripts/check-data-quality.js
   ```

2. **Test Questions**:
   ```bash
   node scripts/test-all-questions.js
   ```

3. **Test Scoring**:
   ```bash
   node scripts/test-scoring-improvements.js
   ```

4. **Test Filtering**:
   ```bash
   node scripts/test-filtering-improvements.js
   ```

5. **Check Browser**:
   - Open `http://localhost:3000/reco`
   - Check console logs
   - Answer questions
   - Verify behavior

---

## üìû Questions to Answer

1. **Why only 4 questions?**
   - Check frequency threshold
   - Check eligible requirement types
   - Verify question generation logic

2. **Are questions meaningful and user-friendly?** ‚ö†Ô∏è **CRITICAL**
   - Check translation keys
   - Verify no jargon (TRL, CAPEX/OPEX, etc.)
   - Test in browser - would a normal user understand?
   - Remove questions that are too technical or vague
   - Verify questions are relevant for funding discovery

3. **Do answers make sense?**
   - Check answer options
   - Verify translations
   - Test answer flow
   - Ensure options are clear and not confusing

4. **Is scoring accurate?**
   - Check score distribution
   - Verify normalization
   - Test with real scenarios

5. **Why database connection failing?**
   - Check server logs
   - Verify DATABASE_URL
   - Test module loading

6. **Which questions should be removed?** ‚ö†Ô∏è **NEW**
   - Review each question for meaningfulness
   - Check if question filters programs effectively
   - Identify questions that are too technical or vague
   - Consider removing: TRL, CAPEX/OPEX, overly vague questions

---

## üéØ Priority Review: Question Meaningfulness

### Must Review Questions

1. **TRL Level** (`trl_level`)
   - ‚ùå Too technical - users don't know what TRL means
   - ‚ùå Should be removed or replaced with simpler question
   - **Recommendation**: Remove or replace with "How developed is your project?" (early/mid/late)

2. **Investment Type** (`investment_type` - CAPEX/OPEX)
   - ‚ùå Too technical - users don't know CAPEX vs OPEX
   - ‚ùå Should be removed or replaced
   - **Recommendation**: Remove or replace with "What do you need funding for?" (equipment/operations/both)

3. **Co-financing** (`co_financing`)
   - ‚ö†Ô∏è May be confusing - users may not understand percentage
   - **Recommendation**: Simplify to "Do you have your own money to invest?" (yes/no)

4. **Innovation Focus** (`innovation_focus`)
   - ‚ö†Ô∏è Too vague - what does "innovation focus" mean?
   - **Recommendation**: Remove or make more specific

5. **Sustainability Focus** (`sustainability_focus`)
   - ‚ö†Ô∏è Too vague - what does this mean?
   - **Recommendation**: Remove or make more specific

6. **Market Size** (`market_size`)
   - ‚ö†Ô∏è May be confusing - local/national/EU/international
   - **Recommendation**: Keep but ensure options are clear

### Likely Keep Questions

1. **Location** ‚úÖ - Essential, clear
2. **Company Age** ‚úÖ - Clear, relevant
3. **Company Type** ‚úÖ - Clear (startup/SME)
4. **Research Focus** ‚úÖ - Clear (research vs commercial)
5. **Impact** ‚úÖ - Clear (purpose)

### Review Process

1. **List all questions**:
   ```bash
   node scripts/test-all-questions.js
   ```

2. **Check filtering effectiveness**:
   ```bash
   node scripts/test-filtering-improvements.js
   ```

3. **Test in browser**:
   - Open `http://localhost:3000/reco`
   - Answer questions
   - For each question, ask: "Would a normal user understand this?"

4. **Review translation keys**:
   - Check `shared/i18n/translations/en.json` and `de.json`
   - Verify all question texts are user-friendly

5. **Make recommendations**:
   - Remove questions that are too technical
   - Remove questions that are too vague
   - Simplify questions that are confusing
   - Keep only questions that are meaningful and clear

---

**Good luck! üçÄ**

